{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jillani/anaconda3/lib/python3.7/site-packages/IPython/core/magics/pylab.py:160: UserWarning: pylab import has clobbered these variables: ['copy', 'split']\n",
      "`%matplotlib` prevents importing * from pylab and numpy\n",
      "  \"\\n`%matplotlib` prevents importing * from pylab and numpy\"\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "import scipy.stats\n",
    "from collections import defaultdict  # default dictionary \n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self,purity,klasslabel='',score=0,split=[],fidx=-1):\n",
    "        self.lchild=None       \n",
    "        self.rchild=None\n",
    "        self.klasslabel=klasslabel        \n",
    "        self.split=split\n",
    "        self.score=score\n",
    "        self.fidx=fidx\n",
    "        self.purity=purity\n",
    "        \n",
    "        \n",
    "    def set_childs(self,lchild,rchild):\n",
    "        \n",
    "        self.lchild=lchild\n",
    "        self.rchild=rchild\n",
    "\n",
    "        \n",
    "    def isleaf(self):\n",
    "        # Your Code Here\n",
    "        if (self.lchild == None and self.rchild == None):\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "      #  print('returns true if the current node is leaf, else returns false')\n",
    "    \n",
    "    def isless_than_eq(self, X):\n",
    "        if (X[self.fidx] < self.split):\n",
    "            return True\n",
    "        return False\n",
    "        \n",
    "    def get_str(self):        \n",
    "        if self.isleaf():\n",
    "            return 'C(class={},Purity={})'.format(self.klasslabel,self.purity)\n",
    "        else:\n",
    "            return 'I(Fidx={},Score={},Split={})'.format(self.fidx,self.score,self.split) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Your code goes here...\n",
    "\n",
    "class DecisionTree:\n",
    "    ''' Implements the Decision Tree For Classification... '''\n",
    "    def __init__(self, purityp, exthreshold,maxdepth=10,tree=None):        \n",
    "        self.purity=purityp\n",
    "        self.exthreshold=exthreshold\n",
    "        self.maxdepth=maxdepth\n",
    "        self.tree=tree\n",
    "        \n",
    "    def train(self, X, Y):\n",
    "        ''' Train Decision Tree using the given \n",
    "            X [m x d] data matrix and Y labels matrix\n",
    "            \n",
    "            Input:\n",
    "            ------\n",
    "            X: [m x d] a data matrix of m d-dimensional examples.\n",
    "            Y: [m x 1] a label vector.\n",
    "            \n",
    "            Returns:\n",
    "            -----------\n",
    "            Nothing\n",
    "            '''\n",
    "        nexamples,nfeatures=X.shape\n",
    "        ## now go and train a model for each class...\n",
    "        # YOUR CODE HERE\n",
    "        self.tree = self.build_tree(X,Y,self.maxdepth)\n",
    "\n",
    "        \n",
    "    def build_tree(self, X, Y, depth):\n",
    "        \"\"\" \n",
    "            Function is used to recursively build the decision Tree \n",
    "          \n",
    "            Input\n",
    "            -----\n",
    "            X: [m x d] a data matrix of m d-dimensional examples.\n",
    "            Y: [m x 1] a label vector.\n",
    "            \n",
    "            Returns\n",
    "            -------\n",
    "            root node of the built tree...\n",
    "        \"\"\"\n",
    "        nexamples, nfeatures=X.shape\n",
    "        (values,counts) = np.unique(Y,return_counts=True)\n",
    "        ind=np.argmax(counts)\n",
    "        current_purity = counts[ind]/Y.shape[0]\n",
    "        klasses,C=np.unique(Y,return_counts=True)\n",
    "        # Base Cond.   \n",
    "        if (depth == 0 or current_purity>=self.purity):\n",
    "            (values,counts) = np.unique(Y,return_counts=True)\n",
    "            ind=np.argmax(counts)\n",
    "            clabel = values[ind]\n",
    "            leaf = Node(current_purity, clabel)\n",
    "            return leaf\n",
    "        \n",
    "        leftN = None\n",
    "        rightN = None\n",
    "        \n",
    "        best_split = 0.0\n",
    "        best_score = 0.0\n",
    "        feature = -1\n",
    "        leftIdx = None\n",
    "        rightIdx = None\n",
    "\n",
    "        for i in range (0, X.shape[1]):\n",
    "            split,mingain,Xlidx,Xridx=self.evaluate_numerical_attribute(X[:,i],Y)\n",
    "            if (mingain > best_score):\n",
    "                best_score = mingain\n",
    "                best_split = split\n",
    "                feature = i\n",
    "                leftIdx = Xlidx\n",
    "                rightIdx = Xridx\n",
    "        n = Node(purity=current_purity,klasslabel='', score=best_score, split=best_split, fidx=feature)\n",
    "        n.lchild = self.build_tree(X[leftIdx], Y[leftIdx], depth-1)\n",
    "        n.rchild = self.build_tree(X[rightIdx], Y[rightIdx], depth-1)\n",
    "        return n\n",
    "        \n",
    "        \n",
    "    def test(self, X):\n",
    "        \n",
    "        ''' Test the trained classifiers on the given set of examples \n",
    "        \n",
    "                   \n",
    "            Input:\n",
    "            ------\n",
    "            X: [m x d] a data matrix of m d-dimensional test examples.\n",
    "           \n",
    "            Returns:\n",
    "            -----------\n",
    "                pclass: the predicted class for each example, i.e. to which it belongs\n",
    "        '''\n",
    "        \n",
    "        nexamples, nfeatures=X.shape\n",
    "        pclasses=self.predict(X)\n",
    "        return pclasses\n",
    "        \n",
    "    def calc_entropy(self, prob1, prob2, prob3):\n",
    "        if (prob1 == 0):\n",
    "            prob1 += 0.0000001\n",
    "        if (prob2 == 0):\n",
    "            prob2 += 0.0000001\n",
    "        if (prob3 == 0):\n",
    "            prob3 += 0.0000001\n",
    "        return - (prob1*math.log(prob1,2) + prob2*math.log(prob2,2) + prob3*math.log(prob3,2))\n",
    "\n",
    "    \n",
    "    def evaluate_numerical_attribute(self,feat, Y):\n",
    "        '''\n",
    "            Evaluates the numerical attribute for all possible split points for\n",
    "            possible feature selection\n",
    "            \n",
    "            Input:\n",
    "            ---------\n",
    "            feat: a contiuous feature\n",
    "            Y: labels\n",
    "            \n",
    "            Returns:\n",
    "            ----------\n",
    "            v: splitting threshold\n",
    "            score: splitting score\n",
    "            Xlidx: Index of examples belonging to left child node\n",
    "            Xridx: Index of examples belonging to right child node\n",
    "            \n",
    "        '''\n",
    "        classes=np.unique(Y)\n",
    "        nclasses=len(classes)\n",
    "        sidx=np.argsort(feat)\n",
    "        f=feat[sidx]\n",
    "        sY=Y[sidx]\n",
    "        split = 0.0\n",
    "        score = 100.0\n",
    "        i_g = 0\n",
    "        p_i = 0.0 \n",
    "        p_j = 0.0 \n",
    "        p_k = 0.0 \n",
    "        \n",
    "        for i in range (0, sY.shape[0]):\n",
    "            if (sY[i] == 'Iris-setosa'):\n",
    "                p_i += 1\n",
    "            elif (sY[i] == 'Iris-versicolor'):\n",
    "                p_j += 1\n",
    "            else:\n",
    "                p_k += 1\n",
    "        entropy = self.calc_entropy(p_i/sY.shape[0], p_j/sY.shape[0], p_k/sY.shape[0])\n",
    "        for j in range(0, sY.shape[0]):\n",
    "            tsplit = f[j]\n",
    "            count_greater = 0\n",
    "            count_lesser = 0\n",
    "            count_i = 0.0  \n",
    "            count_j = 0.0 \n",
    "            count_k = 0.0  \n",
    "\n",
    "            count_l = 0.0 \n",
    "            count_m = 0.0 \n",
    "            count_n = 0.0 \n",
    "            for i in range (0, sY.shape[0]):\n",
    "                if f[i] >= tsplit:\n",
    "                    count_greater += 1\n",
    "                    if (sY[i] == 'Iris-setosa'):\n",
    "                        count_i += 1\n",
    "                    elif (sY[i] == 'Iris-versicolor'):\n",
    "                        count_j += 1\n",
    "                    else:\n",
    "                        count_k += 1\n",
    "                else:\n",
    "                    count_lesser += 1\n",
    "                    if (sY[i] == 'Iris-setosa'):\n",
    "                        count_l += 1\n",
    "                    elif (sY[i] == 'Iris-versicolor'):\n",
    "                        count_m += 1\n",
    "                    else:\n",
    "                        count_n += 1\n",
    "            if (count_greater == 0 or count_lesser == 0):\n",
    "                continue\n",
    "            greater_entropy = self.calc_entropy(count_i/count_greater, count_j/count_greater, count_k/count_greater)\n",
    "            lesser_entropy = self.calc_entropy(count_l/count_lesser, count_m/count_lesser, count_n/count_lesser)\n",
    "            entropy_split = (count_greater/sY.shape[0])*greater_entropy + (count_lesser/sY.shape[0])*lesser_entropy\n",
    "            information_gain = entropy - entropy_split\n",
    "            if (entropy_split < score):\n",
    "                score = entropy_split\n",
    "                i_g = information_gain\n",
    "                split = tsplit\n",
    "        score = i_g\n",
    "        leftChildInd = np.where(f <  split)[0]\n",
    "        RightChildInd = np.where(f >= split)[0]\n",
    "        \n",
    "        return split, score, leftChildInd, RightChildInd          \n",
    "    \n",
    "    def predict(self, X):\n",
    "        \n",
    "        \"\"\"\n",
    "        Test the trained classifiers on the given example X\n",
    "        \n",
    "                   \n",
    "            Input:\n",
    "            ------\n",
    "            X: [1 x d] a d-dimensional test example.\n",
    "           \n",
    "            Returns:\n",
    "            -----------\n",
    "                pclass: the predicted class for the given example, i.e. to which it belongs\n",
    "        \"\"\"\n",
    "        pclass = []\n",
    "        for i in range (0, X.shape[0]):\n",
    "            temp = self._predict(self.tree, X[i,:])\n",
    "            pclass.append(temp)\n",
    "        return pclass\n",
    "    \n",
    "    def _predict(self,node, X):\n",
    "        # YOUR CODE HERE\n",
    "        if (node.isleaf() == True):\n",
    "            temp = node.klasslabel\n",
    "            return temp\n",
    "        else:\n",
    "            if (node.isless_than_eq(X) == True):\n",
    "                return self._predict(node.lchild, X)\n",
    "            else:\n",
    "                return self._predict(node.rchild, X)\n",
    "\n",
    "    def __str__(self):\n",
    "        \n",
    "        return self.__print(self.tree)        \n",
    "        \n",
    "     \n",
    "    def find_depth(self):\n",
    "        \n",
    "        return self._find_depth(self.tree)\n",
    "    \n",
    "    \n",
    "    def _find_depth(self,node):\n",
    "        if not node:\n",
    "            return\n",
    "        if node.isleaf():\n",
    "            return 1\n",
    "        else:\n",
    "            return max(self._find_depth(node.lchild),self._find_depth(node.rchild))+1\n",
    "        \n",
    "    def __print(self,node,depth=0):\n",
    "        \n",
    "        ret = \"\"\n",
    "\n",
    "        # Print right branch\n",
    "        if node.rchild:\n",
    "            ret += self.__print(node.rchild,depth+1)\n",
    "\n",
    "        # Print own value\n",
    "        \n",
    "        ret += \"\\n\" + (\"    \"*depth) + node.get_str()\n",
    "\n",
    "        # Print left branch\n",
    "        if node.lchild:\n",
    "            ret += self.__print(node.lchild,depth+1)\n",
    "        \n",
    "        return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tools as t # set of tools for plotting, data splitting, etc.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       SepalLength  SepalWidth  PetalLength  PetalWidth\n",
      "count   149.000000  149.000000   149.000000  149.000000\n",
      "mean      5.848322    3.051007     3.774497    1.205369\n",
      "std       0.828594    0.433499     1.759651    0.761292\n",
      "min       4.300000    2.000000     1.000000    0.100000\n",
      "25%       5.100000    2.800000     1.600000    0.300000\n",
      "50%       5.800000    3.000000     4.400000    1.300000\n",
      "75%       6.400000    3.300000     5.100000    1.800000\n",
      "max       7.900000    4.400000     6.900000    2.500000\n"
     ]
    }
   ],
   "source": [
    "#load the data set\n",
    "data=pd.read_csv('./iris.data')\n",
    "data.columns=['SepalLength','SepalWidth','PetalLength','PetalWidth','Class']\n",
    "print (data.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Data Set Dimensions= (149, 4)  True Class labels dimensions (149,)\n"
     ]
    }
   ],
   "source": [
    "# Get your data in matrix (X ,Y)\n",
    "temp1 = data[['SepalLength','SepalWidth','PetalLength','PetalWidth']].dropna()\n",
    "temp2 = data['Class'].dropna()\n",
    "X = np.asarray(temp1)\n",
    "Y = np.asarray(temp2)\n",
    "    \n",
    "print (\" Data Set Dimensions=\", X.shape, \" True Class labels dimensions\", Y.shape)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "149\n",
      "5.6\n"
     ]
    }
   ],
   "source": [
    "print (len(Y))\n",
    "feat=[0,1]\n",
    "dt=DecisionTree(0.95,5,2)\n",
    "feat=[0,1]\n",
    "dt.classes=np.unique(Y)\n",
    "dt.nclasses=len(np.unique(Y))\n",
    "split,mingain,Xlidx,Xridx=dt.evaluate_numerical_attribute(X[:,0],Y)\n",
    "print (split)\n",
    "# You should get following result:,\n",
    "# Split=5.45, entropy=0.388707191825"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "149\n",
      "3.0 0.9137533408759091 [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48] [ 49  50  51  52  53  54  55  56  57  58  59  60  61  62  63  64  65  66\n",
      "  67  68  69  70  71  72  73  74  75  76  77  78  79  80  81  82  83  84\n",
      "  85  86  87  88  89  90  91  92  93  94  95  96  97  98  99 100 101 102\n",
      " 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120\n",
      " 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138\n",
      " 139 140 141 142 143 144 145 146 147 148]\n"
     ]
    }
   ],
   "source": [
    "print (len(Y))\n",
    "dt=DecisionTree(0.95,5)\n",
    "dt.train(X[:,feat],Y)\n",
    "g,s,xl,xr=dt.evaluate_numerical_attribute(X[:,2],Y)\n",
    "print (g, s, xl, xr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'c' argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with 'x' & 'y'.  Please use a 2-D array with a single row if you really want to specify the same RGB or RGBA value for all points.\n",
      "'c' argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with 'x' & 'y'.  Please use a 2-D array with a single row if you really want to specify the same RGB or RGBA value for all points.\n",
      "'c' argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with 'x' & 'y'.  Please use a 2-D array with a single row if you really want to specify the same RGB or RGBA value for all points.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Plotting the Decision Surface of Training Set... \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# %pdb\n",
    "print (\" Plotting the Decision Surface of Training Set... \")\n",
    "t.plot_decision_regions(X[:,feat],Y,clf=dt, res=0.1, cycle_marker=True, legend=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Training Data Set Dimensions= (104, 4) Training True Class labels dimensions (104,)\n",
      " Test Data Set Dimensions= (45, 4) Test True Class labels dimensions (104,)\n"
     ]
    }
   ],
   "source": [
    "# Split your data into training and test-set... \n",
    "# see the documentation of split_data in tools for further information...\n",
    "Xtrain,Ytrain,Xtest,Ytest=t.split_data(X,Y)\n",
    "\n",
    "print (\" Training Data Set Dimensions=\", Xtrain.shape, \"Training True Class labels dimensions\", Ytrain.shape)\n",
    "print (\" Test Data Set Dimensions=\", Xtest.shape, \"Test True Class labels dimensions\", Ytrain.shape)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets train a Decision Tree Classifier on Petal Length and Width\n",
    "feat=[0,1]\n",
    "dt=DecisionTree(0.95,5)\n",
    "dt.train(Xtrain[:,feat],Ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets test it on the set of unseen examples...\n",
    "pclasses=dt.predict(Xtest[:,feat])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's See How Good we are doing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31\n",
      "Accuracy =  0.6888888888888889\n"
     ]
    }
   ],
   "source": [
    "#Lets see how good we are doing, by finding the accuracy on the test set..\n",
    "print (np.sum(pclasses==Ytest))\n",
    "print (\"Accuracy = \", np.sum(pclasses==Ytest)/float(Ytest.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lets Train on All 4 Features and all 3 classes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Training Data Set Dimensions= (104, 4) Training True Class labels dimensions (104,)\n",
      " Test Data Set Dimensions= (45, 4) Test True Class labels dimensions (104,)\n"
     ]
    }
   ],
   "source": [
    "# Split your data into training and test-set... \n",
    "# see the documentation of split_data in tools for further information...\n",
    "Xtrain,Ytrain,Xtest,Ytest=t.split_data(X,Y)\n",
    "\n",
    "print (\" Training Data Set Dimensions=\", Xtrain.shape, \"Training True Class labels dimensions\", Ytrain.shape)\n",
    "print (\" Test Data Set Dimensions=\", Xtest.shape, \"Test True Class labels dimensions\", Ytrain.shape)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40\n",
      "Accuracy =  0.8888888888888888\n"
     ]
    }
   ],
   "source": [
    "dt=DecisionTree(0.95,5)\n",
    "dt.train(Xtrain,Ytrain)\n",
    "pclasses=dt.predict(Xtest)\n",
    "#Lets see how good we are doing, by finding the accuracy on the test set..\n",
    "print (np.sum(pclasses==Ytest))\n",
    "print (\"Accuracy = \", np.sum(pclasses==Ytest)/float(Ytest.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
